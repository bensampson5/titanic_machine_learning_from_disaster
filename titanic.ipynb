{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "\n",
    "<img src='https://www.rd.com/wp-content/uploads/2019/08/shutterstock_242291458-1-760x506.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# Main project directories\n",
    "PROJECT_ROOT_DIR = Path.cwd()\n",
    "DATASETS_DIR = PROJECT_ROOT_DIR / 'datasets'\n",
    "DATASETS_TITANIC_DIR = DATASETS_DIR / 'titanic'\n",
    "SUBMISSIONS_DIR = PROJECT_ROOT_DIR / 'submissions'\n",
    "IMAGES_DIR = PROJECT_ROOT_DIR / 'images'\n",
    "\n",
    "# Pretty plots\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Helper functions\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension='png', resolution=300):\n",
    "    path = IMAGES_DIR / (fig_id + '.' + fig_extension)\n",
    "    print('Saving figure', fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = DATASETS_TITANIC_DIR / 'train.csv'\n",
    "TEST_DATA_PATH = DATASETS_TITANIC_DIR / 'test.csv'\n",
    "titanic_train = pd.read_csv(TRAIN_DATA_PATH)  # load titanic train data\n",
    "titanic_test = pd.read_csv(TEST_DATA_PATH)  # load titanic test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ben/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a62f26b0f647079e9eb0535e119a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Summarize dataset', max=26.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336d6b448cb34a86b017073d201c6b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generate report structure', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Render widgets', max=1.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8b50912d104cc9a2ee53220277e45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate initial report on titanic training dataset before any data pre-processing\n",
    "from pandas_profiling import ProfileReport\n",
    "titanic_train_report = ProfileReport(titanic_train, title='Titanic Training Dataset Exploration Report')\n",
    "titanic_train_report.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_no_labels = titanic_train.drop('Survived', axis=1)  # make a copy of titanic_train but without labels\n",
    "titanic_train_labels = titanic_train['Survived'].copy()  # copy all titanic_train labels to a new array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# numerical feature pipeline (Pclass, Age, SibSp, Parch, Fare)\n",
    "features_num = np.array(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare'])\n",
    "pipeline_num = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# 'Sex' feature pipeline\n",
    "features_sex = np.array(['Sex'])\n",
    "pipeline_sex = Pipeline([\n",
    "    ('ord_enc', OrdinalEncoder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# 'Embarked' feature pipeline\n",
    "features_embarked = np.array(['Embarked'])\n",
    "pipeline_embarked = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('one_hot_enc', OneHotEncoder(sparse=False)),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# full data preprocessing pipeline\n",
    "data_preprocessing_pipeline = ColumnTransformer([\n",
    "    ('num', pipeline_num, features_num),\n",
    "    ('sex', pipeline_sex, features_sex),\n",
    "    ('embarked', pipeline_embarked, features_embarked),\n",
    "])\n",
    "\n",
    "# fit data preprocessing pipeline to titanic training data without labels\n",
    "# and transform titanic training data without labels\n",
    "titanic_train_no_labels_preprocessed = data_preprocessing_pipeline.fit_transform(titanic_train_no_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.910000e+02</td>\n",
       "      <td>8.910000e+02</td>\n",
       "      <td>8.910000e+02</td>\n",
       "      <td>8.910000e+02</td>\n",
       "      <td>8.910000e+02</td>\n",
       "      <td>8.910000e+02</td>\n",
       "      <td>8.910000e+02</td>\n",
       "      <td>8.910000e+02</td>\n",
       "      <td>8.910000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.031048e-16</td>\n",
       "      <td>2.562796e-16</td>\n",
       "      <td>3.456519e-16</td>\n",
       "      <td>6.716164e-17</td>\n",
       "      <td>-4.373606e-17</td>\n",
       "      <td>-4.059603e-16</td>\n",
       "      <td>-1.738851e-16</td>\n",
       "      <td>-4.017238e-16</td>\n",
       "      <td>-3.628473e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000562e+00</td>\n",
       "      <td>1.000562e+00</td>\n",
       "      <td>1.000562e+00</td>\n",
       "      <td>1.000562e+00</td>\n",
       "      <td>1.000562e+00</td>\n",
       "      <td>1.000562e+00</td>\n",
       "      <td>1.000562e+00</td>\n",
       "      <td>1.000562e+00</td>\n",
       "      <td>1.000562e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.566107e+00</td>\n",
       "      <td>-2.253155e+00</td>\n",
       "      <td>-4.745452e-01</td>\n",
       "      <td>-4.736736e-01</td>\n",
       "      <td>-6.484217e-01</td>\n",
       "      <td>-1.355574e+00</td>\n",
       "      <td>-4.820427e-01</td>\n",
       "      <td>-3.075623e-01</td>\n",
       "      <td>-1.623803e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.693648e-01</td>\n",
       "      <td>-5.924806e-01</td>\n",
       "      <td>-4.745452e-01</td>\n",
       "      <td>-4.736736e-01</td>\n",
       "      <td>-4.891482e-01</td>\n",
       "      <td>-1.355574e+00</td>\n",
       "      <td>-4.820427e-01</td>\n",
       "      <td>-3.075623e-01</td>\n",
       "      <td>-1.623803e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.273772e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.745452e-01</td>\n",
       "      <td>-4.736736e-01</td>\n",
       "      <td>-3.573909e-01</td>\n",
       "      <td>7.376951e-01</td>\n",
       "      <td>-4.820427e-01</td>\n",
       "      <td>-3.075623e-01</td>\n",
       "      <td>6.158384e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.273772e-01</td>\n",
       "      <td>4.079260e-01</td>\n",
       "      <td>4.327934e-01</td>\n",
       "      <td>-4.736736e-01</td>\n",
       "      <td>-2.424635e-02</td>\n",
       "      <td>7.376951e-01</td>\n",
       "      <td>-4.820427e-01</td>\n",
       "      <td>-3.075623e-01</td>\n",
       "      <td>6.158384e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.273772e-01</td>\n",
       "      <td>3.870872e+00</td>\n",
       "      <td>6.784163e+00</td>\n",
       "      <td>6.974147e+00</td>\n",
       "      <td>9.667167e+00</td>\n",
       "      <td>7.376951e-01</td>\n",
       "      <td>2.074505e+00</td>\n",
       "      <td>3.251373e+00</td>\n",
       "      <td>6.158384e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass           Age         SibSp         Parch          Fare  \\\n",
       "count  8.910000e+02  8.910000e+02  8.910000e+02  8.910000e+02  8.910000e+02   \n",
       "mean  -2.031048e-16  2.562796e-16  3.456519e-16  6.716164e-17 -4.373606e-17   \n",
       "std    1.000562e+00  1.000562e+00  1.000562e+00  1.000562e+00  1.000562e+00   \n",
       "min   -1.566107e+00 -2.253155e+00 -4.745452e-01 -4.736736e-01 -6.484217e-01   \n",
       "25%   -3.693648e-01 -5.924806e-01 -4.745452e-01 -4.736736e-01 -4.891482e-01   \n",
       "50%    8.273772e-01  0.000000e+00 -4.745452e-01 -4.736736e-01 -3.573909e-01   \n",
       "75%    8.273772e-01  4.079260e-01  4.327934e-01 -4.736736e-01 -2.424635e-02   \n",
       "max    8.273772e-01  3.870872e+00  6.784163e+00  6.974147e+00  9.667167e+00   \n",
       "\n",
       "                Sex    Embarked_C    Embarked_Q    Embarked_S  \n",
       "count  8.910000e+02  8.910000e+02  8.910000e+02  8.910000e+02  \n",
       "mean  -4.059603e-16 -1.738851e-16 -4.017238e-16 -3.628473e-16  \n",
       "std    1.000562e+00  1.000562e+00  1.000562e+00  1.000562e+00  \n",
       "min   -1.355574e+00 -4.820427e-01 -3.075623e-01 -1.623803e+00  \n",
       "25%   -1.355574e+00 -4.820427e-01 -3.075623e-01 -1.623803e+00  \n",
       "50%    7.376951e-01 -4.820427e-01 -3.075623e-01  6.158384e-01  \n",
       "75%    7.376951e-01 -4.820427e-01 -3.075623e-01  6.158384e-01  \n",
       "max    7.376951e-01  2.074505e+00  3.251373e+00  6.158384e-01  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rebuild pandas dataframe for preprocessed titanic train data without labels\n",
    "embarked_ohe_categories = data_preprocessing_pipeline.named_transformers_['embarked'].named_steps['one_hot_enc'].categories_[0]\n",
    "embarked_ohe_categories = features_embarked[0] + '_' + embarked_ohe_categories\n",
    "column_names_after_preprocessing = np.concatenate((features_num, features_sex, embarked_ohe_categories))\n",
    "\n",
    "titanic_train_no_labels_preprocessed_df = pd.DataFrame(titanic_train_no_labels_preprocessed, columns=column_names_after_preprocessing)\n",
    "titanic_train_no_labels_preprocessed_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a3864a1e584489ae1b9daaba1f58f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Summarize dataset', max=24.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41e46ca72924170a19cb04baa210193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generate report structure', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Render widgets', max=1.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13e09e08f654e309d5cdb55900c44fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic_train_after_processing = pd.concat([titanic_train_no_labels_preprocessed_df, titanic_train_labels.to_frame()], axis=1)\n",
    "titanic_train_report_after_preprocessing = ProfileReport(titanic_train_after_processing, title='Titanic Training Dataset Exploration Report After Preprocessing')\n",
    "titanic_train_report_after_preprocessing.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit LinearRegression model\n",
      "Fit LogisticRegression model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "# build a models dictionary\n",
    "models = [LinearRegression(), LogisticRegression(solver='lbfgs')]\n",
    "models = dict([(type(model).__name__, model) for model in models])\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(titanic_train_no_labels_preprocessed, titanic_train_labels)\n",
    "    print('Fit ' + name + ' model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearRegression\n",
      "Number of Predictions: 891\n",
      "First five raw predictions: [0.09375837 0.92878034 0.61710431 0.87741925 0.05942609]\n",
      "First five actual predictions: [0. 1. 1. 1. 0.]\n",
      "Absolute Error: 180.0\n",
      "Mean Absolute Error: 0.20202020202020202\n",
      "Percent Correct: 79.8%\n",
      "\n",
      "\n",
      "Model: LogisticRegression\n",
      "Number of Predictions: 891\n",
      "First five raw predictions: [0 1 1 1 0]\n",
      "First five actual predictions: [0 1 1 1 0]\n",
      "Absolute Error: 178\n",
      "Mean Absolute Error: 0.19977553310886645\n",
      "Percent Correct: 80.02%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance on the titanic training dataset\n",
    "\n",
    "for name, model in models.items():\n",
    "    raw_predictions = model.predict(titanic_train_no_labels_preprocessed)\n",
    "    predictions = raw_predictions.copy()\n",
    "    predictions[predictions <= 0.5] = 0\n",
    "    predictions[predictions > 0.5] = 1\n",
    "\n",
    "    ae = np.absolute(predictions - titanic_train_labels.to_numpy()).sum()\n",
    "    mae = ae / len(titanic_train_no_labels_preprocessed)\n",
    "    percent_correct = np.round((1 - mae) * 100, 2)\n",
    "    print('Model:', name)\n",
    "    print('Number of Predictions:', len(titanic_train_no_labels_preprocessed))\n",
    "    print('First five raw predictions:', raw_predictions[:5])\n",
    "    print('First five actual predictions:', predictions[:5])\n",
    "    print('Absolute Error:', ae)\n",
    "    print('Mean Absolute Error:', mae)\n",
    "    print('Percent Correct:', str(percent_correct) + '%')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_preprocessed = data_preprocessing_pipeline.transform(titanic_test)  # just transform, not fit\n",
    "\n",
    "model_test_predictions = dict([(name, None) for name in models.keys()])\n",
    "\n",
    "for name, model in models.items():\n",
    "    titanic_test_predictions = model.predict(titanic_test_preprocessed)\n",
    "\n",
    "    # use 0.5 as threshold to determine if passenger survived (1) or died (0)\n",
    "    titanic_test_predictions[titanic_test_predictions > 0.5] = 1\n",
    "    titanic_test_predictions[titanic_test_predictions <= 0.5] = 0\n",
    "    titanic_test_predictions = titanic_test_predictions.astype('int64')\n",
    "    \n",
    "    model_test_predictions[name] = titanic_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote predictions to submission file: /Users/Ben/code/github/titanic_machine_learning_from_disaster/submissions/submission_LinearRegression_20200526_142926.csv\n",
      "Wrote predictions to submission file: /Users/Ben/code/github/titanic_machine_learning_from_disaster/submissions/submission_LogisticRegression_20200526_142926.csv\n"
     ]
    }
   ],
   "source": [
    "# generate submission\n",
    "for name, predictions in model_test_predictions.items():\n",
    "    submission_filename = 'submission_' + name + '_' + dt.datetime.now().strftime('%Y%m%d_%H%M%S') + '.csv'\n",
    "    submission_path = SUBMISSIONS_DIR / submission_filename\n",
    "    submission_df = titanic_test[['PassengerId']].copy()\n",
    "    submission_df['Survived'] = predictions\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print('Wrote predictions to submission file:', submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
